# LLM Model Configuration for EXAIM
# Environment variables can override these defaults.

# MAS (Multi-Agent System)
# Used by: CDSS demo agents (cardiology, internal_medicine, laboratory, orchestrator, radiology)
# Purpose: Generate reasoning traces from specialized agents
mas:
  provider: google
  model:  gemini-2.5-flash-lite
  streaming: true
  # Env overrides: MAS_LLM_PROVIDER, MAS_LLM_MODEL

# Summarizer - Clinical Summary Generation
# Used by: SummarizerAgent
# Purpose: Generate structured clinical summaries from agent traces
summarizer:
  provider: huggingface
  model: unsloth/medgemma-1.5-4b-it-unsloth-bnb-4bit
  streaming: true
  # Env overrides: SUMMARIZER_LLM_PROVIDER, SUMMARIZER_LLM_MODEL

# Buffer Agent - Trace Trigger Decision
# Used by: BufferAgent
# Purpose: Decide when to trigger summarization based on trace completeness and novelty
# Uses 27B model for rigorous analysis, quantized to 4-bit for memory efficiency
# 
# MEMORY-CONSTRAINED ENVIRONMENTS (HuggingFace Spaces with single GPU):
# If you get OOM errors, set: BUFFER_AGENT_LLM_MODEL=unsloth/medgemma-1.5-4b-it-unsloth-bnb-4bit
# This uses the smaller 4B model instead, reducing memory from ~16GB to ~3GB
buffer_agent:
  provider: huggingface
  model: unsloth/medgemma-27b-text-it-unsloth-bnb-4bit
  streaming: false
  # Env overrides: BUFFER_AGENT_LLM_PROVIDER, BUFFER_AGENT_LLM_MODEL